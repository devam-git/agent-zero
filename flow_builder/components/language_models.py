LANGUAGE_MODEL_TEMPLATE = {
    "description": "Runs a language model given a specified provider. ",
    "display_name": "Language Model",
    "icon": "brain-circuit",
    "base_classes": ["LanguageModel", "Message"],
    "beta": False,
    "conditional_paths": [],
    "custom_fields": {},
    "documentation": "",
    "edited": False,
    "frozen": False,
    "legacy": False,
    "lf_version": "1.4.3",
    "metadata": {},
    "output_types": [],
    "pinned": False,
    "outputs": [
        {
            "allows_loop": False,
            "cache": True,
            "display_name": "Model Response",
            "group_outputs": False,
            "method": "text_response",
            "name": "text_output",
            "selected": "Message",
            "tool_mode": True,
            "types": ["Message"],
            "value": "__UNDEFINED__"
        },
        {
            "allows_loop": False,
            "cache": True,
            "display_name": "Language Model",
            "group_outputs": False,
            "method": "build_model",
            "name": "model_output",
            "selected": "LanguageModel",
            "tool_mode": True,
            "types": ["LanguageModel"],
            "value": "__UNDEFINED__"
        }
    ],
    "field_order": [
        "provider",
        "model_name",
        "api_key",
        "input_value",
        "system_message",
        "stream",
        "temperature"
    ],
    "template": {
        "_type": "Component",
        "api_key": {
            "_input_type": "SecretStrInput",
            "advanced": False,
            "display_name": "OpenAI API Key",
            "dynamic": False,
            "info": "Model Provider API key",
            "input_types": [],
            "load_from_db": True,
            "name": "api_key",
            "password": True,
            "placeholder": "",
            "real_time_refresh": True,
            "required": False,
            "show": True,
            "title_case": False,
            "type": "str",
            "value": ""
        },
        "input_value": {
            "_input_type": "MessageTextInput",
            "advanced": False,
            "display_name": "Input",
            "dynamic": False,
            "info": "The input text to send to the model",
            "input_types": ["Message"],
            "list": False,
            "list_add_label": "Add More",
            "load_from_db": False,
            "name": "input_value",
            "placeholder": "",
            "required": False,
            "show": True,
            "title_case": False,
            "tool_mode": False,
            "trace_as_input": True,
            "trace_as_metadata": True,
            "type": "str",
            "value": ""
        },
        "model_name": {
            "_input_type": "DropdownInput",
            "advanced": False,
            "combobox": False,
            "dialog_inputs": {},
            "display_name": "Model Name",
            "dynamic": False,
            "info": "Select the model to use",
            "name": "model_name",
            "options": [
                "gpt-4o-mini",
                "gpt-4o",
                "gpt-4.1",
                "gpt-4.1-mini",
                "gpt-4.1-nano",
                "gpt-4.5-preview",
                "gpt-4-turbo",
                "gpt-4-turbo-preview",
                "gpt-4",
                "gpt-3.5-turbo"
            ],
            "options_metadata": [],
            "placeholder": "",
            "required": False,
            "show": True,
            "title_case": False,
            "toggle": False,
            "tool_mode": False,
            "trace_as_metadata": True,
            "type": "str",
            "value": "gpt-4o-mini"
        },
        "provider": {
            "_input_type": "DropdownInput",
            "advanced": False,
            "combobox": False,
            "dialog_inputs": {},
            "display_name": "Model Provider",
            "dynamic": False,
            "info": "Select the model provider",
            "name": "provider",
            "options": ["OpenAI", "Anthropic", "Google"],
            "options_metadata": [
                {"icon": "OpenAI"},
                {"icon": "Anthropic"},
                {"icon": "Google"}
            ],
            "placeholder": "",
            "real_time_refresh": True,
            "required": False,
            "show": True,
            "title_case": False,
            "toggle": False,
            "tool_mode": False,
            "trace_as_metadata": True,
            "type": "str",
            "value": "OpenAI"
        },
        "stream": {
            "_input_type": "BoolInput",
            "advanced": True,
            "display_name": "Stream",
            "dynamic": False,
            "info": "Whether to stream the response",
            "list": False,
            "list_add_label": "Add More",
            "name": "stream",
            "placeholder": "",
            "required": False,
            "show": True,
            "title_case": False,
            "tool_mode": False,
            "trace_as_metadata": True,
            "type": "bool",
            "value": False
        },
        "system_message": {
            "_input_type": "MessageTextInput",
            "advanced": False,
            "display_name": "System Message",
            "dynamic": False,
            "info": "A system message that helps set the behavior of the assistant",
            "input_types": ["Message"],
            "list": False,
            "list_add_label": "Add More",
            "load_from_db": False,
            "name": "system_message",
            "placeholder": "",
            "required": False,
            "show": True,
            "title_case": False,
            "tool_mode": False,
            "trace_as_input": True,
            "trace_as_metadata": True,
            "type": "str",
            "value": ""
        },
        "temperature": {
            "_input_type": "SliderInput",
            "advanced": True,
            "display_name": "Temperature",
            "dynamic": False,
            "info": "Controls randomness in responses",
            "max_label": "",
            "max_label_icon": "",
            "min_label": "",
            "min_label_icon": "",
            "name": "temperature",
            "placeholder": "",
            "range_spec": {
                "max": 1,
                "min": 0,
                "step": 0.01,
                "step_type": "float"
            },
            "required": False,
            "show": True,
            "slider_buttons": False,
            "slider_buttons_options": [],
            "slider_input": False,
            "title_case": False,
            "tool_mode": False,
            "type": "slider",
            "value": 0.1
        },
        "code": {
            "advanced": True,
            "dynamic": True,
            "fileTypes": [],
            "file_path": "",
            "info": "",
            "list": False,
            "load_from_db": False,
            "multiline": True,
            "name": "code",
            "password": False,
            "placeholder": "",
            "required": True,
            "show": True,
            "title_case": False,
            "type": "code",
            "value": "from typing import Any\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\n\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\nfrom langflow.schema.dotdict import dotdict\n\n\nclass LanguageModelComponent(LCModelComponent):\n    display_name = \"Language Model\"\n    description = \"Runs a language model given a specified provider. \"\n    icon = \"brain-circuit\"\n    category = \"models\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        DropdownInput(\n            name=\"provider\",\n            display_name=\"Model Provider\",\n            options=[\"OpenAI\", \"Anthropic\", \"Google\"],\n            value=\"OpenAI\",\n            info=\"Select the model provider\",\n            real_time_refresh=True,\n            options_metadata=[{\"icon\": \"OpenAI\"}, {\"icon\": \"Anthropic\"}, {\"icon\": \"Google\"}],\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n            info=\"Select the model to use\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"Model Provider API key\",\n            required=False,\n            show=True,\n            real_time_refresh=True,\n        ),\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n            info=\"The input text to send to the model\",\n        ),\n        MultilineInput(\n            name=\"system_message\",\n            display_name=\"System Message\",\n            info=\"A system message that helps set the behavior of the assistant\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"stream\",\n            display_name=\"Stream\",\n            info=\"Whether to stream the response\",\n            value=False,\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            info=\"Controls randomness in responses\",\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            advanced=True,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:\n        provider = self.provider\n        model_name = self.model_name\n        temperature = self.temperature\n        stream = self.stream\n\n        if provider == \"OpenAI\":\n            if not self.api_key:\n                msg = \"OpenAI API key is required when using OpenAI provider\"\n                raise ValueError(msg)\n            return ChatOpenAI(\n                model_name=model_name,\n                temperature=temperature,\n                streaming=stream,\n                openai_api_key=self.api_key,\n            )\n        if provider == \"Anthropic\":\n            if not self.api_key:\n                msg = \"Anthropic API key is required when using Anthropic provider\"\n                raise ValueError(msg)\n            return ChatAnthropic(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                anthropic_api_key=self.api_key,\n            )\n        if provider == \"Google\":\n            if not self.api_key:\n                msg = \"Google API key is required when using Google provider\"\n                raise ValueError(msg)\n            return ChatGoogleGenerativeAI(\n                model=model_name,\n                temperature=temperature,\n                streaming=stream,\n                google_api_key=self.api_key,\n            )\n        msg = f\"Unknown provider: {provider}\"\n        raise ValueError(msg)\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"provider\":\n            if field_value == \"OpenAI\":\n                build_config[\"model_name\"][\"options\"] = OPENAI_MODEL_NAMES\n                build_config[\"model_name\"][\"value\"] = OPENAI_MODEL_NAMES[0]\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\n            elif field_value == \"Anthropic\":\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\n            elif field_value == \"Google\":\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\n        return build_config\n"
        }
    },
    "tool_mode": False
}